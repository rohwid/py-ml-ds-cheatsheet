{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Autoencoder?\n",
    "\n",
    "Autoencoder is **a neural network model that has the same input and output**. The autoencoder studies the input data and attempts to reconstruct the input data.\n",
    "\n",
    "Then what's the use of Autoencoder? Autoencoder is used to **reduce the dimensions of features (Dimensionality Reduction)**. If the data form by very high dimension (data with a very large number of features). For example, it can be each feature spread over each dimension of the data, so that each of the existing data looks very different. To overcome these problems require very much data or reduce the dimensions of the data. PCA can be use here, t-SNE, or Autoencoder.\n",
    "\n",
    "<img src=\"img/decoder.png\">\n",
    "\n",
    "Autoencoder consists of two main parts, **encoder** and **decoder**. Between the encoder and decoder, there is a **code layer**. The number of neurons in the code layer is **the number of dimensions that expect to reduce the dimensions of our data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Code\n",
    "\n",
    "For the example of implementation, the MNIST data will be used as dimensionality reduction example. MNIST is a dataset consisting of numbers from 0 to 9 written by hand.\n",
    "\n",
    "<img src=\"img/mnist.png\">\n",
    "\n",
    "MNIST data has often been used as a benchmark whether a model can recognize or classify these numbers. Each data is an image measuring 28x28 pixels so that there are a total of 784 dimensions and it will be reduce to 16x16 pixel only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency\n",
    "\n",
    "The dependency that needed in the autoencoder which is exemplified this time was almost same with the example in the previous parts. But this time MNIST data will be loaded from a package that has been provided by Keras. Because the important of new optimizers that gonna be try, that is ADAM.\n",
    "\n",
    "**ADAM is a variant of the other gradient descent algorithm**, for more details you might read it yourself in the paper [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Activation, Dense\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.python.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The data from **MNIST is a grayscale image with a range from 0 to 255**. This range of data is \"too big\" for our model, especially with a **fairly small learning rate**, so the data need to be scaling by dividing it by 255. So the new range will be got in between 0 and 1.\n",
    "\n",
    "After that, 784 vector the previous dimension of input will be change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Save MNIST Dataset\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "# Scale from 0 to 1\n",
    "train_x = train_x.astype('float32') / 255.\n",
    "test_x = test_x.astype('float32') / 255.\n",
    "\n",
    "# Reshape from 28x28 matrix to 784 vector\n",
    "train_x = np.reshape(train_x, (len(train_x), np.prod(train_x.shape[1:])))\n",
    "test_x = np.reshape(test_x, (len(test_x), np.prod(test_x.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Autoencoder\n",
    "\n",
    "As explained above, an autoencoder consists of an encoder and decoder. **The number of neurons in each layer of the encoder is** `784-256-128-64-32-16` and for **the decoder is** `16-32-64-128-256-784`.\n",
    "\n",
    "The optimizer that used was `ADAM` with a learning rate of 0.001 and the Loss function that will be used was `binary_crossentropy`. Why crossentropy?\n",
    "\n",
    "***The data we have has a range from 0 to 1, the activation function at the output layer is also sigmoid which has a range from 0 to 1. It is all identical to the probability distribution, so we can think of this as a classification problem and we can use binary crossentropy.***\n",
    "\n",
    "***Actually we can also think of this as a regression using Linear activation at the output layer, but the loss function that we use must be MSE (Mean Squared Error). Later the results will be compared at the end of this part.***\n",
    "\n",
    "Also remember if the autoencoder is trying to reconstruct the input data, so the target that will be use is the input itself (`train_x` and `test_x`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid & Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2659 - val_loss: 0.2107\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1809 - val_loss: 0.1638\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1564 - val_loss: 0.1498\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1455 - val_loss: 0.1413\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1392 - val_loss: 0.1355\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1337 - val_loss: 0.1313\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1297 - val_loss: 0.1270\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1258 - val_loss: 0.1235\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1229 - val_loss: 0.1208\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1204 - val_loss: 0.1193\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1182 - val_loss: 0.1166\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1164 - val_loss: 0.1155\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1145 - val_loss: 0.1128\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1129 - val_loss: 0.1119\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1116 - val_loss: 0.1105\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1105 - val_loss: 0.1098\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1096 - val_loss: 0.1089\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1088 - val_loss: 0.1082\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1082 - val_loss: 0.1076\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1076 - val_loss: 0.1077\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1070 - val_loss: 0.1066\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1064 - val_loss: 0.1063\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1059 - val_loss: 0.1059\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1055 - val_loss: 0.1053\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1051 - val_loss: 0.1050\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1047 - val_loss: 0.1049\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 92us/sample - loss: 0.1043 - val_loss: 0.1051\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1040 - val_loss: 0.1045\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1036 - val_loss: 0.1041\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1034 - val_loss: 0.1038\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1029 - val_loss: 0.1036\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1027 - val_loss: 0.1028\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1022 - val_loss: 0.1024\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1017 - val_loss: 0.1022\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1013 - val_loss: 0.1014\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1008 - val_loss: 0.1018\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.1003 - val_loss: 0.1014\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1000 - val_loss: 0.1009\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0996 - val_loss: 0.1004\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0993 - val_loss: 0.0997\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0989 - val_loss: 0.0994\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0986 - val_loss: 0.0993\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0983 - val_loss: 0.0998\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0979 - val_loss: 0.0988\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0977 - val_loss: 0.0988\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0974 - val_loss: 0.0992\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0973 - val_loss: 0.0977\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0970 - val_loss: 0.0982\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0968 - val_loss: 0.0981\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0966 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0963 - val_loss: 0.0978\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0962 - val_loss: 0.0981\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0960 - val_loss: 0.0975\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0959 - val_loss: 0.0968\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0957 - val_loss: 0.0980\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0955 - val_loss: 0.0975\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0954 - val_loss: 0.0964\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0953 - val_loss: 0.0966\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0951 - val_loss: 0.0962\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0949 - val_loss: 0.0964\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0949 - val_loss: 0.0959\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0947 - val_loss: 0.0964\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0945 - val_loss: 0.0967\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0946 - val_loss: 0.0960\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0944 - val_loss: 0.0960\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0943 - val_loss: 0.0964\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0942 - val_loss: 0.0959\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0940 - val_loss: 0.0965\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0941 - val_loss: 0.0956\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0938 - val_loss: 0.0954\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0937 - val_loss: 0.0957\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0937 - val_loss: 0.0956\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0936 - val_loss: 0.0952\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0935 - val_loss: 0.0951\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0935 - val_loss: 0.0954\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0934 - val_loss: 0.0951\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0933 - val_loss: 0.0952\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0932 - val_loss: 0.0959\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0931 - val_loss: 0.0951\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0931 - val_loss: 0.0959\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0930 - val_loss: 0.0948\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0930 - val_loss: 0.0948\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0928 - val_loss: 0.0953\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0929 - val_loss: 0.0951\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0927 - val_loss: 0.0951\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0927 - val_loss: 0.0945\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0926 - val_loss: 0.0947\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0926 - val_loss: 0.0945\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0924 - val_loss: 0.0944\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0924 - val_loss: 0.0943\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0924 - val_loss: 0.0946\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0923 - val_loss: 0.0947\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0923 - val_loss: 0.0944\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0923 - val_loss: 0.0945\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0922 - val_loss: 0.0946\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0921 - val_loss: 0.0941\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0920 - val_loss: 0.0942\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0920 - val_loss: 0.0940\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0920 - val_loss: 0.0943\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0919 - val_loss: 0.0941\n"
     ]
    }
   ],
   "source": [
    "# Target Dimension\n",
    "TARGET_DIM = 16\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(784,))\n",
    "h_encode = Dense(256, activation='relu')(inputs)\n",
    "h_encode = Dense(128, activation='relu')(h_encode)\n",
    "h_encode = Dense(64, activation='relu')(h_encode)\n",
    "h_encode = Dense(32, activation='relu')(h_encode)\n",
    "\n",
    "# Coded\n",
    "encoded = Dense(TARGET_DIM, activation='relu')(h_encode)\n",
    "\n",
    "# Decoder\n",
    "h_decode = Dense(32, activation='relu')(encoded)\n",
    "h_decode = Dense(64, activation='relu')(h_decode)\n",
    "h_decode = Dense(128, activation='relu')(h_decode)\n",
    "h_decode = Dense(256, activation='relu')(h_decode)\n",
    "outputs = Dense(784, activation='sigmoid')(h_decode)\n",
    "\n",
    "# Autoencoder Model\n",
    "autoencoder = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Encoder Model\n",
    "encoder = Model(inputs=inputs, outputs=encoded)\n",
    "\n",
    "# Optimizer / Update Rule\n",
    "adam = Adam(lr=0.001)\n",
    "\n",
    "# Compile the model Binary Crossentropy\n",
    "autoencoder.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "# Train and Save weight\n",
    "autoencoder.fit(train_x, train_x, batch_size=256, epochs=100, verbose=1, shuffle=True, \n",
    "                validation_data=(test_x, test_x))\n",
    "\n",
    "autoencoder.save_weights('6_autoencoder_weights_sigmoid_cross-entropy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Result\n",
    "\n",
    "After the training is finished, digits 0 through 9 in the test data will be reconstruct.\n",
    "\n",
    "The output of the encoder can be also take which is a feature whose dimensions have been reduced. This feature can later be used for classification to see how the quality is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoded Data\n",
    "encoded_train = encoder.predict(train_x)\n",
    "encoded_test = encoder.predict(test_x)\n",
    "\n",
    "# Reconstructed Data\n",
    "reconstructed = autoencoder.predict(test_x)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        if i == test_y[count]:\n",
    "            # Original\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(test_x[count].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "            # Reconstructed\n",
    "            ax = plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(reconstructed[count].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            \n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            break;\n",
    "            \n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Sigmoid - Cross-Entropy. **After 100 epochs**, the amount of **loss/validation loss** is **0.0923/0.0950** cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if the prediction results are converted into images, the quality of reconstruction from Sigmoid-Cross-Entropy has better quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

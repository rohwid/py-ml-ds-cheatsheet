{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Network\n",
    "\n",
    "Previous validation Accuracy is 88.9%. What if the validation accuracy improvement at least 90%?\n",
    "\n",
    "So, the more \"deep\" architecture by adding convolutional layer can be used. But must be remember, if the more deeper the architecture that gonna be used, the more longer the training process taken. Because the more parameters that must be updated, but architecture like this is also prone to be overfit.\n",
    "\n",
    "<img src=\"img/cnn_deeper_model.jpg\">\n",
    "\n",
    "The second model that will try was used same filter size which is 5x5 and 3x3, but the smaller stride has used and did downsampling process twice. Just remember, the more smaller **stride**, then more information can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
    "\n",
    "train_x = train_x.astype('float32') / 255.\n",
    "test_x = test_x.astype('float32') / 255.\n",
    "\n",
    "train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
    "test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
    "\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 197,610\n",
      "Trainable params: 197,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction Layer\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "conv_layer = ZeroPadding2D(padding=(2,2))(inputs)\n",
    "conv_layer = Conv2D(16, (5, 5), strides=(1,1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)\n",
    "\n",
    "# Flatten feature map to Vector with 576 element.\n",
    "flatten = Flatten()(conv_layer)\n",
    "\n",
    "# Fully Connected Layer\n",
    "fc_layer = Dense(256, activation='relu')(flatten)\n",
    "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
    "outputs = Dense(10, activation='softmax')(fc_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Adam Optimizer and Cross Entropy Loss\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print Model Summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Two Models\n",
    "\n",
    "By using TensorBoard, we can also compare the performance of the two models that we have trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 28s 469us/step - loss: 1.2461 - accuracy: 0.5875 - val_loss: 0.7724 - val_accuracy: 0.7189\n",
      "WARNING:tensorflow:From /home/rohwid/PyEnvironment/tf-1.15-all-package-py.3.6/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 28s 458us/step - loss: 0.6760 - accuracy: 0.7437 - val_loss: 0.6438 - val_accuracy: 0.7552\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.5920 - accuracy: 0.7777 - val_loss: 0.5788 - val_accuracy: 0.7834\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.5454 - accuracy: 0.7984 - val_loss: 0.5361 - val_accuracy: 0.8026\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 29s 492us/step - loss: 0.5123 - accuracy: 0.8113 - val_loss: 0.5134 - val_accuracy: 0.8143\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.4854 - accuracy: 0.8230 - val_loss: 0.4941 - val_accuracy: 0.8256\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.4663 - accuracy: 0.8317 - val_loss: 0.4759 - val_accuracy: 0.8227\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.4446 - accuracy: 0.8413 - val_loss: 0.4577 - val_accuracy: 0.8340\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.4312 - accuracy: 0.8454 - val_loss: 0.4450 - val_accuracy: 0.8429\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.4169 - accuracy: 0.8516 - val_loss: 0.4339 - val_accuracy: 0.8444\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.4046 - accuracy: 0.8557 - val_loss: 0.4125 - val_accuracy: 0.8537\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.3938 - accuracy: 0.8596 - val_loss: 0.4053 - val_accuracy: 0.8579\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 33s 548us/step - loss: 0.3811 - accuracy: 0.8649 - val_loss: 0.3972 - val_accuracy: 0.8607\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.3712 - accuracy: 0.8696 - val_loss: 0.3876 - val_accuracy: 0.8628\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 29s 488us/step - loss: 0.3694 - accuracy: 0.8681 - val_loss: 0.3860 - val_accuracy: 0.8605\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 29s 480us/step - loss: 0.3575 - accuracy: 0.8728 - val_loss: 0.3772 - val_accuracy: 0.8638\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.3506 - accuracy: 0.8758 - val_loss: 0.3696 - val_accuracy: 0.8682\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 29s 487us/step - loss: 0.3445 - accuracy: 0.8762 - val_loss: 0.3637 - val_accuracy: 0.8724\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 29s 484us/step - loss: 0.3365 - accuracy: 0.8808 - val_loss: 0.3581 - val_accuracy: 0.8716\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 29s 486us/step - loss: 0.3317 - accuracy: 0.8812 - val_loss: 0.3535 - val_accuracy: 0.8751\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 29s 485us/step - loss: 0.3282 - accuracy: 0.8814 - val_loss: 0.3508 - val_accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.3212 - accuracy: 0.8860 - val_loss: 0.3443 - val_accuracy: 0.8785\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.3177 - accuracy: 0.8867 - val_loss: 0.3467 - val_accuracy: 0.8758\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 29s 487us/step - loss: 0.3145 - accuracy: 0.8872 - val_loss: 0.3409 - val_accuracy: 0.8802\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 30s 492us/step - loss: 0.3084 - accuracy: 0.8893 - val_loss: 0.3354 - val_accuracy: 0.8819\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 29s 485us/step - loss: 0.3054 - accuracy: 0.8903 - val_loss: 0.3337 - val_accuracy: 0.8829\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 30s 494us/step - loss: 0.3019 - accuracy: 0.8918 - val_loss: 0.3281 - val_accuracy: 0.8842\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 29s 485us/step - loss: 0.3003 - accuracy: 0.8921 - val_loss: 0.3232 - val_accuracy: 0.8835\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.2926 - accuracy: 0.8952 - val_loss: 0.3224 - val_accuracy: 0.8841\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 28s 475us/step - loss: 0.2895 - accuracy: 0.8969 - val_loss: 0.3272 - val_accuracy: 0.8829\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.2888 - accuracy: 0.8957 - val_loss: 0.3342 - val_accuracy: 0.8813\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 27s 452us/step - loss: 0.2850 - accuracy: 0.8982 - val_loss: 0.3219 - val_accuracy: 0.8849\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.2841 - accuracy: 0.8975 - val_loss: 0.3131 - val_accuracy: 0.8892\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.2779 - accuracy: 0.8998 - val_loss: 0.3163 - val_accuracy: 0.8869\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 27s 454us/step - loss: 0.2745 - accuracy: 0.9013 - val_loss: 0.3160 - val_accuracy: 0.8869\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 27s 458us/step - loss: 0.2718 - accuracy: 0.9027 - val_loss: 0.3052 - val_accuracy: 0.8902\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.2716 - accuracy: 0.9016 - val_loss: 0.3174 - val_accuracy: 0.8861\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 33s 551us/step - loss: 0.2669 - accuracy: 0.9033 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 33s 555us/step - loss: 0.2652 - accuracy: 0.9043 - val_loss: 0.3149 - val_accuracy: 0.8866\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 33s 557us/step - loss: 0.2627 - accuracy: 0.9060 - val_loss: 0.2987 - val_accuracy: 0.8935\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.2590 - accuracy: 0.9066 - val_loss: 0.2992 - val_accuracy: 0.8926\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 31s 517us/step - loss: 0.2565 - accuracy: 0.9074 - val_loss: 0.3132 - val_accuracy: 0.8869\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 31s 520us/step - loss: 0.2532 - accuracy: 0.9087 - val_loss: 0.3179 - val_accuracy: 0.8786\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 31s 516us/step - loss: 0.2506 - accuracy: 0.9092 - val_loss: 0.2932 - val_accuracy: 0.8941\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 34s 565us/step - loss: 0.2503 - accuracy: 0.9086 - val_loss: 0.3014 - val_accuracy: 0.8897\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.2462 - accuracy: 0.9108 - val_loss: 0.2930 - val_accuracy: 0.8958\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 27s 451us/step - loss: 0.2430 - accuracy: 0.9119 - val_loss: 0.2889 - val_accuracy: 0.8977\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.2403 - accuracy: 0.9124 - val_loss: 0.2902 - val_accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2413 - accuracy: 0.9115 - val_loss: 0.2964 - val_accuracy: 0.8950\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.2362 - accuracy: 0.9139 - val_loss: 0.2918 - val_accuracy: 0.8953\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2337 - accuracy: 0.9154 - val_loss: 0.2806 - val_accuracy: 0.9001\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2326 - accuracy: 0.9157 - val_loss: 0.2913 - val_accuracy: 0.8951\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.2311 - accuracy: 0.9157 - val_loss: 0.2894 - val_accuracy: 0.8957\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.2305 - accuracy: 0.9159 - val_loss: 0.2796 - val_accuracy: 0.8994\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2281 - accuracy: 0.9179 - val_loss: 0.2795 - val_accuracy: 0.9008\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.2241 - accuracy: 0.9189 - val_loss: 0.2858 - val_accuracy: 0.8990\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.2235 - accuracy: 0.9188 - val_loss: 0.2820 - val_accuracy: 0.8994\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2201 - accuracy: 0.9193 - val_loss: 0.2758 - val_accuracy: 0.9030\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2191 - accuracy: 0.9197 - val_loss: 0.2785 - val_accuracy: 0.9013\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.2167 - accuracy: 0.9209 - val_loss: 0.2874 - val_accuracy: 0.8990\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.2143 - accuracy: 0.9218 - val_loss: 0.2727 - val_accuracy: 0.9026\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.2117 - accuracy: 0.9218 - val_loss: 0.2712 - val_accuracy: 0.9041\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.2095 - accuracy: 0.9230 - val_loss: 0.2774 - val_accuracy: 0.9028\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.2098 - accuracy: 0.9230 - val_loss: 0.2756 - val_accuracy: 0.9013\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.2058 - accuracy: 0.9248 - val_loss: 0.2732 - val_accuracy: 0.9039\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.2066 - accuracy: 0.9234 - val_loss: 0.2730 - val_accuracy: 0.9036\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.2024 - accuracy: 0.9258 - val_loss: 0.2705 - val_accuracy: 0.9039\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.2004 - accuracy: 0.9271 - val_loss: 0.2734 - val_accuracy: 0.9062\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.2006 - accuracy: 0.9270 - val_loss: 0.2809 - val_accuracy: 0.9022\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1989 - accuracy: 0.9270 - val_loss: 0.2830 - val_accuracy: 0.8994\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1946 - accuracy: 0.9289 - val_loss: 0.2652 - val_accuracy: 0.9076\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1953 - accuracy: 0.9288 - val_loss: 0.2752 - val_accuracy: 0.9057\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1927 - accuracy: 0.9294 - val_loss: 0.2825 - val_accuracy: 0.9017\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.1890 - accuracy: 0.9304 - val_loss: 0.2703 - val_accuracy: 0.9073\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1883 - accuracy: 0.9304 - val_loss: 0.2703 - val_accuracy: 0.9049\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 27s 442us/step - loss: 0.1881 - accuracy: 0.9312 - val_loss: 0.2697 - val_accuracy: 0.9064\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.1857 - accuracy: 0.9324 - val_loss: 0.2729 - val_accuracy: 0.9056\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.1834 - accuracy: 0.9334 - val_loss: 0.2652 - val_accuracy: 0.9086\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.2697 - val_accuracy: 0.9074\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1816 - accuracy: 0.9326 - val_loss: 0.2687 - val_accuracy: 0.9073\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.1780 - accuracy: 0.9349 - val_loss: 0.2682 - val_accuracy: 0.9080\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 26s 442us/step - loss: 0.1764 - accuracy: 0.9354 - val_loss: 0.2781 - val_accuracy: 0.9052\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1743 - accuracy: 0.9361 - val_loss: 0.2741 - val_accuracy: 0.9071\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1726 - accuracy: 0.9363 - val_loss: 0.2693 - val_accuracy: 0.9052\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.1725 - accuracy: 0.9370 - val_loss: 0.2656 - val_accuracy: 0.9098\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1707 - accuracy: 0.9385 - val_loss: 0.2684 - val_accuracy: 0.9091\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1700 - accuracy: 0.9375 - val_loss: 0.2671 - val_accuracy: 0.9061\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1687 - accuracy: 0.9382 - val_loss: 0.2759 - val_accuracy: 0.9051\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1669 - accuracy: 0.9384 - val_loss: 0.2760 - val_accuracy: 0.9060\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.1670 - accuracy: 0.9388 - val_loss: 0.2832 - val_accuracy: 0.9051\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1640 - accuracy: 0.9399 - val_loss: 0.2861 - val_accuracy: 0.8993\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 26s 442us/step - loss: 0.1630 - accuracy: 0.9415 - val_loss: 0.2806 - val_accuracy: 0.9058\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1603 - accuracy: 0.9409 - val_loss: 0.2614 - val_accuracy: 0.9113\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.1571 - accuracy: 0.9429 - val_loss: 0.2706 - val_accuracy: 0.9106\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1574 - accuracy: 0.9426 - val_loss: 0.2740 - val_accuracy: 0.9072\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 27s 442us/step - loss: 0.1552 - accuracy: 0.9432 - val_loss: 0.2669 - val_accuracy: 0.9113\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.1551 - accuracy: 0.9436 - val_loss: 0.2811 - val_accuracy: 0.9051\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.1536 - accuracy: 0.9432 - val_loss: 0.2667 - val_accuracy: 0.9115\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 27s 442us/step - loss: 0.1524 - accuracy: 0.9438 - val_loss: 0.2678 - val_accuracy: 0.9112\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.1516 - accuracy: 0.9451 - val_loss: 0.2703 - val_accuracy: 0.9094\n"
     ]
    }
   ],
   "source": [
    "# Use TensorBoard\n",
    "callbacks = TensorBoard(log_dir='./Graph')\n",
    "\n",
    "# Train for 100 Epochs and use TensorBoard Callback\n",
    "model.fit(train_x, train_y, batch_size=256, epochs=100, verbose=1, validation_data=(test_x, test_y), callbacks=[callbacks])\n",
    "\n",
    "# Save Weights\n",
    "model.save_weights('7_more_deeper_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tf_board_cnn_compare.png\">\n",
    "\n",
    "The blue graph is the graph of the second model using more convolution layers. Can be seen there if the performance of this model is clearly better than the first model.\n",
    "\n",
    "Training and Validation Loss obtained were 0.1521 and 0.2571, while Training and Validation Accuracy were 94.46% and 91.28%.\n",
    "\n",
    "Actually both of these models can still be optimized again, you can try to use a higher learning rate for example 0.001, but even smaller epoch or setting the number of neurons in the FC Layer and much more to improve the performance of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
